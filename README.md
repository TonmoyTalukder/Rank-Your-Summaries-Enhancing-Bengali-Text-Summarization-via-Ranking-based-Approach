# Rank-Your-Summaries-Enhancing-Bengali-Text-Summarization-via-Ranking-based-Approach



## Pretrained Models
We have used bellow pre-trained models for summarization:
- mT5 (mT5 XLSum, mT5 CrossSum, mT5 Shahidul)
- BERT (scibert uncased)

We have used BERT (BanglaBERT) for summary ranking purposes.

## Code
You will find the codes of this project inside the "Codes" folder. You need to install specific libraries mentioned in the Notebook to run the code.

## Data
You will find both of the datasets used in this project inside the "Data" folder. We have used one Huggingface Dataset and another from Kaggle. For the second one, you need to download it first. 
